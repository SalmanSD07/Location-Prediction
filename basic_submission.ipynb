{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Salman Ali Sayyed\n",
        "\n",
        "**Student ID**:  220663575\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "**Basic component**\n",
        "\n",
        "The problem that we are about to solve is to classify the input audio file into indoor or outdoor audio. For this a machine learning model will be built. The model will classify audio into indoor and outdoor based on certain features of audio file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 3 Machine Learning pipeline\n",
        "\n",
        "For the first solution of binary classification, following steps had been taken\n",
        "\n",
        "1. **Data Load**: For this step all the zip files of audio data had been uploaded to google drive and then been extracted to the single folder which in this case was 1_dataset on google drive. Then all the files with .wav extension had been read using python's glob package and stored in a variable files.\n",
        "2. **Reading csv**: The csv with the labels and the files name had been read and analysed.\n",
        "3. **Feature extraction**: To extract the feature of audio file two function namely getPitch and getXy had been initiated. Using the python's librosa package spectral features of audio such as spectral centroid, bandwidth, contrast, flatness, rolloff along with audip power, pitch mean and pitch standard deviation had been inserted in a list to define predictors. And a boolean which states weather a particular audio file in indoor or not was considered as label\n",
        "4. **Splitting dataset**: The predictors and labels had been splitted into train and validation set using sklearn\n",
        "5. **Selecting Model**: After trying and  adjusting certain hyperparameters of various classifiers. Our model had been narrowed down to RandomForestClassifier with the hyperparameter as the code below.\n",
        "6. **Validation**: Performace of the model is analyzed based on accuracy, precision, recall and f1-score which are displayed using sklearn's classification report "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwI9kgrfScRh"
      },
      "source": [
        "Note\n",
        "The code to load and extract the data and feature extraction is just for demonstration as it has already been done and stored ia csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2k3jHVoScRh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os,sys,re,pickle,glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkdA789nScRk"
      },
      "outputs": [],
      "source": [
        "directory_to_extract_to = '/content/drive/MyDrive/Data/ml_full_dataset/1_dataset'\n",
        "zip_path_1 = '/content/drive/MyDrive/Data/ml_full_dataset/MLEndLS_1.zip'\n",
        "zip_path_2 = '/content/drive/MyDrive/Data/ml_full_dataset/MLEndLS_2.zip'\n",
        "zip_path_3 = '/content/drive/MyDrive/Data/ml_full_dataset/MLEndLS_3.zip'\n",
        "zip_path_4 = '/content/drive/MyDrive/Data/ml_full_dataset/MLEndLS_4.zip'\n",
        "zip_path_5 = '/content/drive/MyDrive/Data/ml_full_dataset/MLEndLS_5.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "    \n",
        "with zipfile.ZipFile(zip_path_2, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "    \n",
        "with zipfile.ZipFile(zip_path_3, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "    \n",
        "with zipfile.ZipFile(zip_path_4, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "with zipfile.ZipFile(zip_path_5, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "    \n",
        "directory_path='/content/drive/MyDrive/Data/ml_full_dataset/1_dataset/*.wav'\n",
        "files=glob.glob(directory_path)\n",
        "\n",
        "MLEndLS=pd.read_csv('./MLEndLS.csv').set_index('file_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "# 4 Transformation stage\n",
        "Transformations done are as follow\n",
        "\n",
        "1. Label transformation\n",
        "Since we only want to know weather the audio is of indoor or outdoor we had transformed the labels into boolean wich states weather it is indoor or not.\n",
        "\n",
        "2. Feature extraction\n",
        "All outdoor recording must be noisy as compared to indoor hence spectral features will have higher value for outdoor than indoors. Therefore spectral features such as spectral centroid,bandwidth, contrast, flatness and rolloff are used in predictors\n",
        "\n",
        "3. Feature transformation\n",
        "As all the features extracted are in the form of numpy array therefore there mean is taken and used as predictors.\n",
        "As after applying principle component analysis accuracy was decreasing hence it's not been implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPCQbTixScRl"
      },
      "outputs": [],
      "source": [
        "def getPitch(x,fs,winLen=0.02):\n",
        "  #winLen = 0.02 \n",
        "  p = winLen*fs\n",
        "  frame_length = int(2**int(p-1).bit_length())\n",
        "  hop_length = frame_length//2\n",
        "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
        "                                                 frame_length=frame_length,hop_length=hop_length)\n",
        "  return f0,voiced_flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNYwSgreScRm"
      },
      "outputs": [],
      "source": [
        "def getXy(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
        "  X,y =[],[]\n",
        "  for file in tqdm(files):\n",
        "    fileID = file.split('/')[-1]\n",
        "    file_name = file.split('/')[-1]\n",
        "    yi = labels_file.loc[fileID]['in_out']=='indoor'\n",
        "\n",
        "    fs = None # if None, fs would be 22050\n",
        "    x, fs = librosa.load(file,sr=fs)\n",
        "    spectralCentroid=librosa.feature.spectral_centroid(y=x,sr=fs)\n",
        "    spectral_bandwidth=librosa.feature.spectral_bandwidth(y=x,sr=fs)\n",
        "    spectral_contrast=librosa.feature.spectral_contrast(y=x,sr=fs)\n",
        "    spectral_flatness=librosa.feature.spectral_flatness(y=x)\n",
        "    spectral_rolloff=librosa.feature.spectral_rolloff(y=x,sr=fs)\n",
        "    if scale_audio: x = x/np.max(np.abs(x))\n",
        "    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
        "      \n",
        "    power = np.sum(x**2)/len(x)\n",
        "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
        "    voiced_fr = np.mean(voiced_flag)\n",
        "\n",
        "    xi = [power,pitch_mean,pitch_std,voiced_fr,np.mean(spectralCentroid),np.mean(spectral_bandwidth),np.mean(spectral_contrast),np.mean(spectral_flatness),np.mean(spectral_rolloff)]\n",
        "    X.append(xi)\n",
        "    y.append(yi)\n",
        "\n",
        "  return np.array(X),np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Or8f5hGJScRm"
      },
      "outputs": [],
      "source": [
        "X,y = getXy(files, labels_file=MLEndLS, scale_audio=True, onlySingleDigit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8db4cyQfScRm"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pickle\n",
        "\n",
        "with open(\"X.csv\",\"w+\") as my_csv:\n",
        "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
        "    csvWriter.writerows(X)\n",
        "    \n",
        "with open(\"y\", \"wb\") as fp:\n",
        "  pickle.dump(y, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mErnS3aFScRn",
        "outputId": "b160df9a-5bcf-438d-d193-9f1a35942e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2491, 9)\n",
            "(2491,)\n"
          ]
        }
      ],
      "source": [
        "X=pd.read_csv('X.csv')\n",
        "with open(\"y\", \"rb\") as fp:\n",
        "  y=pickle.load(fp)\n",
        "\n",
        "y=np.delete(y,0)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "# 5 Modelling\n",
        "\n",
        "1. **Random Forest Classifier**: Random Forest Classifier was trained as it handles non-linearity of parameters effectively. As it was giving better accuracy as compared to SVM, Decision Tree Classifier and Logistic Regression it was choosen. The hyperparameters max_features=9, max_depth=13 and n_estimators=100 had been taken based on the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz9N9bNgScRn",
        "outputId": "445384e7-cdf8-4129-8efd-5c431ede0bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=13, max_features=9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.3)\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# model=DecisionTreeClassifier()\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model=RandomForestClassifier(max_features=9,max_depth=13,n_estimators=100)\n",
        "\n",
        "# from sklearn import svm\n",
        "# model=svm.SVC(C=0.1, gamma=2)\n",
        "\n",
        "model.fit(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 6 Methodology\n",
        "\n",
        "The performance of the model is analysed based on certain scores or results which are as follows\n",
        "1. **Accuracy**: Its the ratio of correct predictions by the total number of predictions.\n",
        "2. **Precision**: It's the ratio of true positives over the sum of true positives and false positives\n",
        "3. **Recall**: It's the ratio of true positives over the sum of true positives and false negatives\n",
        "4. **F1-score**: It combines these threee metrices into one single matrix that ranges from 0 to 1 and it takes into account both precision and recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 7 Dataset\n",
        "\n",
        "1. 2491 audio files had been used in total\n",
        "2. Input feature extraction and labelling is done for all of them.\n",
        "3. Data is then divided into training and validation into 70:30 ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 8 Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhPpUQo4ScRo",
        "outputId": "90cc5332-ecba-4de4-af80-cf2b26bf666a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.9948364888123924\n",
            "Validation  Accuracy 0.6270053475935828\n",
            "Training Precision= 0.9975669099756691\n",
            "Training Recall= 0.9915356711003628\n",
            "Training f1-score= 0.9945421467556095\n",
            "Validation Precision= 0.5536723163841808\n",
            "Validation Recall= 0.6182965299684543\n",
            "Validation f1-score= 0.5842026825633383\n",
            "Training classification report               precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.99      1.00       921\n",
            "        True       0.99      1.00      0.99       822\n",
            "\n",
            "    accuracy                           0.99      1743\n",
            "   macro avg       0.99      0.99      0.99      1743\n",
            "weighted avg       0.99      0.99      0.99      1743\n",
            "\n",
            "Validation classification report               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.63      0.69      0.66       394\n",
            "        True       0.62      0.55      0.58       354\n",
            "\n",
            "    accuracy                           0.63       748\n",
            "   macro avg       0.63      0.62      0.62       748\n",
            "weighted avg       0.63      0.63      0.63       748\n",
            "\n"
          ]
        }
      ],
      "source": [
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "\n",
        "from sklearn.metrics import classification_report,precision_score,recall_score,f1_score\n",
        "\n",
        "print(\"Training Precision=\",precision_score(yt_p,y_train))\n",
        "print(\"Training Recall=\",recall_score(yt_p,y_train))\n",
        "print(\"Training f1-score=\",f1_score(yt_p,y_train))\n",
        "\n",
        "print(\"Validation Precision=\",precision_score(yv_p,y_val))\n",
        "print(\"Validation Recall=\",recall_score(yv_p,y_val))\n",
        "print(\"Validation f1-score=\",f1_score(yv_p,y_val))\n",
        "print(\"Training classification report\",classification_report(y_train, yt_p))\n",
        "print(\"Validation classification report\",classification_report(y_val, yv_p))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "mean = X_train.mean(0)\n",
        "sd =  X_train.std(0)\n",
        "\n",
        "X_train = (X_train-mean)/sd\n",
        "X_val  = (X_val-mean)/sd\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "yt_p = model.predict(X_train)\n",
        "yv_p = model.predict(X_val)\n",
        "\n",
        "print('Training Accuracy', np.mean(yt_p==y_train))\n",
        "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
        "print(\"Training Precision=\",precision_score(yt_p,y_train))\n",
        "print(\"Training Recall=\",recall_score(yt_p,y_train))\n",
        "print(\"Training f1-score=\",f1_score(yt_p,y_train))\n",
        "\n",
        "print(\"Validation Precision=\",precision_score(yv_p,y_val))\n",
        "print(\"Validation Recall=\",recall_score(yv_p,y_val))\n",
        "print(\"Validation f1-score=\",f1_score(yv_p,y_val))\n",
        "print(\"Training classification report\",classification_report(y_train, yt_p))\n",
        "print(\"Validation classification report\",classification_report(y_val, yv_p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvjRgbCQTcWi",
        "outputId": "6543d1a7-1f14-4997-ef60-a2120a2cb1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy 0.9948364888123924\n",
            "Validation  Accuracy 0.6270053475935828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.99      1.00       921\n",
            "        True       0.99      1.00      0.99       822\n",
            "\n",
            "    accuracy                           0.99      1743\n",
            "   macro avg       0.99      0.99      0.99      1743\n",
            "weighted avg       0.99      0.99      0.99      1743\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.63      0.69      0.66       394\n",
            "        True       0.62      0.55      0.58       354\n",
            "\n",
            "    accuracy                           0.63       748\n",
            "   macro avg       0.63      0.62      0.62       748\n",
            "weighted avg       0.63      0.63      0.63       748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 9 Conclusions\n",
        "\n",
        "After training different models and comparing them through the defined metrices RandomForestClassifier was found to be the best\n",
        "Since we have an imbalanced dataset where number of outdoor labels are more than indoor therefore we cannot rely on accuracy and we do need to compute the precision and recall to get the better understanding regarding the performance of our model.\n",
        "The scores of the model before and after normalization are as follows:\n",
        "\n",
        "**Before normalization**\n",
        "\n",
        "Training Accuracy=0.9942627653471027\n",
        "\n",
        "Training precision=0.9975669099756691\n",
        "\n",
        "Training recall=0.9915356711003628\n",
        "\n",
        "Training f1-score= 0.9945421467556095\n",
        "\n",
        "Validation accuracy=0.6350267379679144\n",
        "\n",
        "Validation precision=0.5536723163841808\n",
        "\n",
        "Validation recall=0.6182965299684543\n",
        "\n",
        "Validation f1-score=0.5842026825633383\n",
        "\n",
        "**After Normalization\n",
        "\n",
        "Training Accuracy=0.9959839357429718\n",
        "\n",
        "Training Precision=0.9987775061124694\n",
        "\n",
        "Training Recall=0.9927095990279465\n",
        "\n",
        "Training f1-score=0.9957343083485679\n",
        "\n",
        "Validation Accuracy=0.6283422459893048\n",
        "\n",
        "Validation Precision=0.5698324022346368\n",
        "\n",
        "Validation Recall=0.6219512195121951\n",
        "\n",
        "Validation f1-score=0.5947521865889213\n",
        "\n",
        "Since these scores are better before normalization than that after normalization therefore I had choosen not to normalze the data and stick to these sets of results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVAsnYa6ScRo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}